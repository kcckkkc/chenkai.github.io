{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7ceada9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Fold 1 训练集RMSE: 0.14739952907244208, 训练集R2: 0.970065792806136\n",
      "Fold 1 测试集RMSE: 0.41672755077870427, 测试集R2: 0.7435949677920212\n",
      "Fold 2\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      "Fold 2 训练集RMSE: 0.15772732603513964, 训练集R2: 0.965774832513743\n",
      "Fold 2 测试集RMSE: 0.4339801778088852, 测试集R2: 0.7219250267677393\n",
      "Fold 3\n",
      "5/5 [==============================] - 0s 1000us/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Fold 3 训练集RMSE: 0.15239444293413698, 训练集R2: 0.9673664680725699\n",
      "Fold 3 测试集RMSE: 0.3956737753012719, 测试集R2: 0.7688485346956094\n",
      "Fold 4\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Fold 4 训练集RMSE: 0.16056511006191537, 训练集R2: 0.9609573541065475\n",
      "Fold 4 测试集RMSE: 0.41054007742668663, 测试集R2: 0.7511525257964689\n",
      "Fold 5\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Fold 5 训练集RMSE: 0.15752610210494283, 训练集R2: 0.9442687937100619\n",
      "Fold 5 测试集RMSE: 0.6325051378711345, 测试集R2: 0.4093227659294194\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# 导入训练集和测试集\n",
    "train_data = pd.read_excel(r'C:\\Users\\k\\Desktop\\硕士论文\\ORP\\ORP4\\ORP_function_train.xlsx')\n",
    "test_data = pd.read_excel(r'C:\\Users\\k\\Desktop\\硕士论文\\ORP\\ORP4\\ORP_function_test.xlsx')\n",
    "\n",
    "# 分离特征和目标变量\n",
    "X_train, y_train = train_data.drop(['E','File'], axis=1), train_data['E']\n",
    "X_test, y_test = test_data.drop(['E','File'], axis=1), test_data['E']\n",
    "\n",
    "# 构建神经网络模型\n",
    "def build_model(input_shape):\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Input(shape=(input_shape,)),\n",
    "        keras.layers.Dense(128, activation='relu', kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(64, activation='relu', kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "        keras.layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='sgd', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# k折交叉验证\n",
    "kf = KFold(n_splits=5)\n",
    "fold_no = 1\n",
    "for train_index, val_index in kf.split(X_train):\n",
    "    print(f'Fold {fold_no}')\n",
    "\n",
    "    # 分割训练集和验证集\n",
    "    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "    \n",
    "    # 构建模型\n",
    "    model = build_model(X_train.shape[1])\n",
    "    \n",
    "    # 训练模型\n",
    "    model.fit(X_train_fold, y_train_fold, epochs=2000, batch_size=20, validation_data=(X_val_fold, y_val_fold), verbose=0)  # verbose设置为0，减少输出\n",
    "    \n",
    "    # 预测\n",
    "    y_train_pred = model.predict(X_train_fold)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # 计算RMSE和R2\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train_fold, y_train_pred))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "    \n",
    "    train_r2 = r2_score(y_train_fold, y_train_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    print(f\"Fold {fold_no} 训练集RMSE: {train_rmse}, 训练集R2: {train_r2}\")\n",
    "    print(f\"Fold {fold_no} 测试集RMSE: {test_rmse}, 测试集R2: {test_r2}\")\n",
    "    \n",
    "    fold_no += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0e4fbc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | dropou... |  l2_reg   | learni... |\n",
      "-------------------------------------------------------------\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m-2.302   \u001b[0m | \u001b[0m0.2668   \u001b[0m | \u001b[0m0.07231  \u001b[0m | \u001b[0m0.001011 \u001b[0m |\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "| \u001b[0m2        \u001b[0m | \u001b[0m-2.452   \u001b[0m | \u001b[0m0.2209   \u001b[0m | \u001b[0m0.01553  \u001b[0m | \u001b[0m0.01014  \u001b[0m |\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m-2.575   \u001b[0m | \u001b[0m0.1745   \u001b[0m | \u001b[0m0.03521  \u001b[0m | \u001b[0m0.04028  \u001b[0m |\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m-2.581   \u001b[0m | \u001b[0m0.3155   \u001b[0m | \u001b[0m0.0425   \u001b[0m | \u001b[0m0.06884  \u001b[0m |\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 966us/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m-2.341   \u001b[0m | \u001b[0m0.1818   \u001b[0m | \u001b[0m0.08793  \u001b[0m | \u001b[0m0.003711 \u001b[0m |\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m-2.496   \u001b[0m | \u001b[0m0.2503   \u001b[0m | \u001b[0m0.0792   \u001b[0m | \u001b[0m0.07767  \u001b[0m |\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m-2.401   \u001b[0m | \u001b[0m0.3129   \u001b[0m | \u001b[0m0.07895  \u001b[0m | \u001b[0m0.01832  \u001b[0m |\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "| \u001b[95m8        \u001b[0m | \u001b[95m-2.296   \u001b[0m | \u001b[95m0.2833   \u001b[0m | \u001b[95m0.08234  \u001b[0m | \u001b[95m0.001    \u001b[0m |\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m-2.693   \u001b[0m | \u001b[0m0.191    \u001b[0m | \u001b[0m0.0164   \u001b[0m | \u001b[0m0.09478  \u001b[0m |\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "| \u001b[95m10       \u001b[0m | \u001b[95m-2.238   \u001b[0m | \u001b[95m0.3905   \u001b[0m | \u001b[95m0.07313  \u001b[0m | \u001b[95m0.02027  \u001b[0m |\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m-2.542   \u001b[0m | \u001b[0m0.2881   \u001b[0m | \u001b[0m0.04293  \u001b[0m | \u001b[0m0.04772  \u001b[0m |\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m-2.302   \u001b[0m | \u001b[0m0.2837   \u001b[0m | \u001b[0m0.07982  \u001b[0m | \u001b[0m0.002903 \u001b[0m |\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "| \u001b[0m13       \u001b[0m | \u001b[0m-3.694   \u001b[0m | \u001b[0m0.2955   \u001b[0m | \u001b[0m0.08428  \u001b[0m | \u001b[0m0.09793  \u001b[0m |\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "| \u001b[0m14       \u001b[0m | \u001b[0m-2.507   \u001b[0m | \u001b[0m0.229    \u001b[0m | \u001b[0m0.07659  \u001b[0m | \u001b[0m0.08584  \u001b[0m |\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "| \u001b[0m15       \u001b[0m | \u001b[0m-3.161   \u001b[0m | \u001b[0m0.442    \u001b[0m | \u001b[0m0.07222  \u001b[0m | \u001b[0m0.09129  \u001b[0m |\n",
      "=============================================================\n",
      "Best Hyperparameters: {'dropout_rate': 0.3905024207524881, 'l2_reg': 0.07313258937121851, 'learning_rate': 0.02027411512664525}\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "训练集RMSE: 0.30514583689980324, 训练集R2: 0.8581183791105117\n",
      "测试集RMSE: 0.4236110181094256, 测试集R2: 0.7350544604657799\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from bayes_opt import BayesianOptimization\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# 导入训练集和测试集\n",
    "train_data = pd.read_excel(r'C:\\Users\\k\\Desktop\\硕士论文\\ORP\\ORP4\\ORP_function_train.xlsx')\n",
    "test_data = pd.read_excel(r'C:\\Users\\k\\Desktop\\硕士论文\\ORP\\ORP4\\ORP_function_test.xlsx')\n",
    "\n",
    "# 分离特征和目标变量\n",
    "X_train, y_train = train_data.drop(['E','File'], axis=1), train_data['E']\n",
    "X_test, y_test = test_data.drop(['E','File'], axis=1), test_data['E']\n",
    "\n",
    "# 定义神经网络模型\n",
    "def build_model(learning_rate, dropout_rate, l2_reg):\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Input(shape=(X_train.shape[1],)),\n",
    "        keras.layers.Dense(128, activation='relu', kernel_regularizer=keras.regularizers.l2(l2_reg)),\n",
    "        keras.layers.Dropout(dropout_rate),\n",
    "        keras.layers.Dense(64, activation='relu', kernel_regularizer=keras.regularizers.l2(l2_reg)),\n",
    "        keras.layers.Dense(1)\n",
    "    ])\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# 定义贝叶斯优化目标函数\n",
    "def bayesian_optimization(learning_rate, dropout_rate, l2_reg):\n",
    "    model = build_model(learning_rate, dropout_rate, l2_reg)\n",
    "\n",
    "    kf = KFold(n_splits=5)\n",
    "    fold_no = 1\n",
    "    total_rmse = 0.0\n",
    "\n",
    "    for train_index, val_index in kf.split(X_train):\n",
    "        X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "        y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "\n",
    "        model.fit(X_train_fold, y_train_fold, epochs=2000, batch_size=20, verbose=0)\n",
    "        y_val_pred = model.predict(X_val_fold)\n",
    "\n",
    "        fold_rmse = np.sqrt(mean_squared_error(y_val_fold, y_val_pred))\n",
    "        total_rmse += fold_rmse\n",
    "\n",
    "    return -total_rmse  # Minimize the negative RMSE\n",
    "\n",
    "# 设置贝叶斯优化的搜索范围\n",
    "param_bounds = {'learning_rate': (0.001, 0.1), 'dropout_rate': (0.1, 0.5), 'l2_reg': (0.001, 0.1)}\n",
    "\n",
    "# 初始化贝叶斯优化对象\n",
    "optimizer = BayesianOptimization(f=bayesian_optimization, pbounds=param_bounds, random_state=1)\n",
    "\n",
    "# 运行贝叶斯优化\n",
    "optimizer.maximize(init_points=5, n_iter=10)\n",
    "\n",
    "# 输出最佳超参数\n",
    "best_params = optimizer.max['params']\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# 使用最佳超参数构建最终模型\n",
    "best_model = build_model(best_params['learning_rate'], best_params['dropout_rate'], best_params['l2_reg'])\n",
    "\n",
    "# 训练最终模型\n",
    "best_model.fit(X_train, y_train, epochs=2000, batch_size=20, verbose=0)\n",
    "\n",
    "# 使用最终模型进行预测和评估\n",
    "y_train_pred = best_model.predict(X_train)\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"训练集RMSE: {train_rmse}, 训练集R2: {train_r2}\")\n",
    "print(f\"测试集RMSE: {test_rmse}, 测试集R2: {test_r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b75021",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
